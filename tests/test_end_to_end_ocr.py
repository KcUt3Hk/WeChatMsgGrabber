#!/usr/bin/env python3
# -*- coding: utf-8 -*-

"""
ç«¯åˆ°ç«¯OCRå¤„ç†æµç¨‹æµ‹è¯•
æµ‹è¯•ä»å›¾åƒè¾“å…¥åˆ°OCRç»“æœè¾“å‡ºçš„å®Œæ•´æµç¨‹
"""

import os
import sys
import time
import numpy as np
import pytest
from PIL import Image, ImageDraw, ImageFont

# æ·»åŠ é¡¹ç›®æ ¹ç›®å½•åˆ°Pythonè·¯å¾„
sys.path.insert(0, os.path.dirname(os.path.dirname(os.path.abspath(__file__))))

from services.ocr_processor import OCRProcessor, OCRConfig
from services.image_preprocessor import ImagePreprocessor


def create_test_image_with_text(text, width=400, height=200, font_size=24):
    """
    åˆ›å»ºåŒ…å«æŒ‡å®šæ–‡æœ¬çš„æµ‹è¯•å›¾åƒ
    
    Args:
        text: è¦æ˜¾ç¤ºçš„æ–‡æœ¬
        width: å›¾åƒå®½åº¦
        height: å›¾åƒé«˜åº¦
        font_size: å­—ä½“å¤§å°
        
    Returns:
        PIL.Imageå¯¹è±¡
    """
    # åˆ›å»ºç™½è‰²èƒŒæ™¯å›¾åƒ
    image = Image.new('RGB', (width, height), 'white')
    draw = ImageDraw.Draw(image)
    
    try:
        # å°è¯•ä½¿ç”¨ç³»ç»Ÿå­—ä½“
        font = ImageFont.truetype("/System/Library/Fonts/PingFang.ttc", font_size)
    except:
        try:
            # å¤‡ç”¨å­—ä½“
            font = ImageFont.truetype("/System/Library/Fonts/Arial.ttf", font_size)
        except:
            # ä½¿ç”¨é»˜è®¤å­—ä½“
            font = ImageFont.load_default()
    
    # è®¡ç®—æ–‡æœ¬ä½ç½®ï¼ˆå±…ä¸­ï¼‰
    bbox = draw.textbbox((0, 0), text, font=font)
    text_width = bbox[2] - bbox[0]
    text_height = bbox[3] - bbox[1]
    x = (width - text_width) // 2
    y = (height - text_height) // 2
    
    # ç»˜åˆ¶é»‘è‰²æ–‡æœ¬
    draw.text((x, y), text, fill='black', font=font)
    
    return image


@pytest.mark.slow
def test_end_to_end_ocr_processing():
    """æµ‹è¯•å®Œæ•´çš„ç«¯åˆ°ç«¯OCRå¤„ç†æµç¨‹"""
    print("=== æµ‹è¯•ç«¯åˆ°ç«¯OCRå¤„ç†æµç¨‹ ===")
    
    # åˆ›å»ºOCRé…ç½®
    config = OCRConfig(
        language="ch",
        confidence_threshold=0.3,
        use_gpu=False
    )
    
    # åˆ›å»ºOCRå¤„ç†å™¨
    processor = OCRProcessor(config)
    
    # åˆå§‹åŒ–OCRå¼•æ“
    print("åˆå§‹åŒ–OCRå¼•æ“...")
    start_time = time.time()
    assert processor.initialize_engine(), "OCRå¼•æ“åˆå§‹åŒ–å¤±è´¥"
    init_time = time.time() - start_time
    print(f"OCRå¼•æ“åˆå§‹åŒ–å®Œæˆï¼Œè€—æ—¶: {init_time:.2f}s")
    
    # åˆ›å»ºæµ‹è¯•å›¾åƒ
    test_texts = [
        "Hello World 123",
        "ä½ å¥½ä¸–ç•Œæµ‹è¯•",
        "OCRæ€§èƒ½æµ‹è¯•456",
        "å¤šè¯­è¨€æ··åˆEnglishä¸­æ–‡"
    ]
    
    test_images = []
    for text in test_texts:
        test_images.append(create_test_image_with_text(text))
    
    # æµ‹è¯•æ¯ä¸ªå›¾åƒ
    all_results = []
    processing_times = []
    
    for i, (text, image) in enumerate(zip(test_texts, test_images)):
        print(f"\nå¤„ç†å›¾åƒ {i+1}/{len(test_texts)}: '{text}'")
        
        # ä¿å­˜åŸå§‹å›¾åƒï¼ˆç”¨äºè°ƒè¯•ï¼‰
        image_path = f"/tmp/test_image_{i}.png"
        image.save(image_path)
        
        # å¤„ç†å›¾åƒ
        start_time = time.time()
        result = processor.process_image(image)
        processing_time = time.time() - start_time
        processing_times.append(processing_time)
        
        # è®°å½•ç»“æœ
        all_results.append({
            'original_text': text,
            'ocr_text': result.text.strip(),
            'confidence': result.confidence,
            'processing_time': processing_time,
            'has_text': len(result.text.strip()) > 0
        })
        
        print(f"  OCRç»“æœ: '{result.text.strip()}'")
        print(f"  ç½®ä¿¡åº¦: {result.confidence:.3f}")
        print(f"  å¤„ç†æ—¶é—´: {processing_time:.3f}s")
        print(f"  æ£€æµ‹åˆ°æ–‡æœ¬: {len(result.text.strip()) > 0}")
    
    # åˆ†æç»“æœ
    print("\n=== ç»“æœåˆ†æ ===")
    
    total_images = len(test_images)
    successful_ocr = sum(1 for r in all_results if r['has_text'])
    success_rate = successful_ocr / total_images
    
    avg_processing_time = np.mean(processing_times)
    min_processing_time = np.min(processing_times)
    max_processing_time = np.max(processing_times)
    
    print(f"æ€»å¤„ç†å›¾åƒæ•°: {total_images}")
    print(f"æˆåŠŸOCRå›¾åƒæ•°: {successful_ocr}")
    print(f"OCRæˆåŠŸç‡: {success_rate:.2%}")
    print(f"å¹³å‡å¤„ç†æ—¶é—´: {avg_processing_time:.3f}s")
    print(f"æœ€çŸ­å¤„ç†æ—¶é—´: {min_processing_time:.3f}s")
    print(f"æœ€é•¿å¤„ç†æ—¶é—´: {max_processing_time:.3f}s")
    
    # éªŒè¯åŸºæœ¬è¦æ±‚
    assert success_rate >= 0.5, f"OCRæˆåŠŸç‡è¿‡ä½: {success_rate:.2%} < 50%"
    assert avg_processing_time < 5.0, f"å¹³å‡å¤„ç†æ—¶é—´è¿‡é•¿: {avg_processing_time:.3f}s >= 5s"
    
    # æ˜¾ç¤ºè¯¦ç»†ç»“æœ
    print("\n=== è¯¦ç»†ç»“æœ ===")
    for i, result in enumerate(all_results):
        print(f"å›¾åƒ {i+1}:")
        print(f"  åŸå§‹æ–‡æœ¬: '{result['original_text']}'")
        print(f"  OCRæ–‡æœ¬: '{result['ocr_text']}'")
        print(f"  åŒ¹é…åº¦: {calculate_text_similarity(result['original_text'], result['ocr_text']):.2%}")
        print(f"  ç½®ä¿¡åº¦: {result['confidence']:.3f}")
        print(f"  å¤„ç†æ—¶é—´: {result['processing_time']:.3f}s")
    
    print("âœ… ç«¯åˆ°ç«¯OCRå¤„ç†æµç¨‹æµ‹è¯•é€šè¿‡")
    return True


def calculate_text_similarity(text1, text2):
    """
    è®¡ç®—ä¸¤ä¸ªæ–‡æœ¬çš„ç›¸ä¼¼åº¦
    
    Args:
        text1: ç¬¬ä¸€ä¸ªæ–‡æœ¬
        text2: ç¬¬äºŒä¸ªæ–‡æœ¬
        
    Returns:
        ç›¸ä¼¼åº¦ç™¾åˆ†æ¯” (0.0 - 1.0)
    """
    if not text1 or not text2:
        return 0.0
    
    # ç®€å•çš„å­—ç¬¦åŒ¹é…ç›¸ä¼¼åº¦è®¡ç®—
    set1 = set(text1)
    set2 = set(text2)
    
    if not set1 or not set2:
        return 0.0
    
    intersection = set1.intersection(set2)
    union = set1.union(set2)
    
    return len(intersection) / len(union) if union else 0.0


@pytest.mark.slow
def test_image_preprocessing_impact():
    """æµ‹è¯•å›¾åƒé¢„å¤„ç†å¯¹OCRæ•ˆæœçš„å½±å“"""
    print("\n=== æµ‹è¯•å›¾åƒé¢„å¤„ç†å¯¹OCRæ•ˆæœçš„å½±å“ ===")
    
    config = OCRConfig(
        language="ch",
        confidence_threshold=0.3,
        use_gpu=False
    )
    
    processor = OCRProcessor(config)
    assert processor.initialize_engine(), "OCRå¼•æ“åˆå§‹åŒ–å¤±è´¥"
    
    # åˆ›å»ºæµ‹è¯•å›¾åƒ
    test_image = create_test_image_with_text("é¢„å¤„ç†æµ‹è¯•æ–‡æœ¬")
    
    # æµ‹è¯•ä¸åŒé¢„å¤„ç†é…ç½®
    preprocessing_configs = [
        {"name": "æ— é¢„å¤„ç†", "enhance_contrast": False, "reduce_noise": False},
        {"name": "ä»…å¯¹æ¯”åº¦å¢å¼º", "enhance_contrast": True, "reduce_noise": False},
        {"name": "ä»…é™å™ª", "enhance_contrast": False, "reduce_noise": True},
        {"name": "å®Œæ•´é¢„å¤„ç†", "enhance_contrast": True, "reduce_noise": True}
    ]
    
    results = []
    
    for config in preprocessing_configs:
        print(f"\næµ‹è¯•é…ç½®: {config['name']}")
        
        # åº”ç”¨é¢„å¤„ç†é…ç½®
        processor.config.enhance_contrast = config['enhance_contrast']
        processor.config.reduce_noise = config['reduce_noise']
        
        start_time = time.time()
        result = processor.process_image(test_image)
        processing_time = time.time() - start_time
        
        results.append({
            'config': config['name'],
            'text': result.text.strip(),
            'confidence': result.confidence,
            'processing_time': processing_time
        })
        
        print(f"  OCRç»“æœ: '{result.text.strip()}'")
        print(f"  ç½®ä¿¡åº¦: {result.confidence:.3f}")
        print(f"  å¤„ç†æ—¶é—´: {processing_time:.3f}s")
    
    # åˆ†æé¢„å¤„ç†æ•ˆæœ
    print("\n=== é¢„å¤„ç†æ•ˆæœåˆ†æ ===")
    for result in results:
        print(f"{result['config']}: ç½®ä¿¡åº¦={result['confidence']:.3f}, æ—¶é—´={result['processing_time']:.3f}s")
    
    print("âœ… å›¾åƒé¢„å¤„ç†å½±å“æµ‹è¯•å®Œæˆ")
    return True


@pytest.mark.slow
def test_batch_processing_performance():
    """æµ‹è¯•æ‰¹é‡å¤„ç†æ€§èƒ½"""
    print("\n=== æµ‹è¯•æ‰¹é‡å¤„ç†æ€§èƒ½ ===")
    
    config = OCRConfig(
        language="ch",
        confidence_threshold=0.3,
        use_gpu=False
    )
    
    processor = OCRProcessor(config)
    assert processor.initialize_engine(), "OCRå¼•æ“åˆå§‹åŒ–å¤±è´¥"
    
    # åˆ›å»ºæ‰¹é‡æµ‹è¯•å›¾åƒ
    batch_size = 10
    test_images = [create_test_image_with_text(f"æ‰¹é‡æµ‹è¯•{i}") for i in range(batch_size)]
    
    # æ‰¹é‡å¤„ç†
    print(f"å¤„ç† {batch_size} å¼ å›¾åƒ...")
    
    start_time = time.time()
    batch_results = []
    
    for i, image in enumerate(test_images):
        result = processor.process_image(image)
        batch_results.append(result)
        print(f"å›¾åƒ {i+1}: '{result.text.strip()}' (ç½®ä¿¡åº¦: {result.confidence:.3f})")
    
    total_time = time.time() - start_time
    avg_time = total_time / batch_size
    
    print(f"\næ‰¹é‡å¤„ç†å®Œæˆ:")
    print(f"æ€»æ—¶é—´: {total_time:.2f}s")
    print(f"å¹³å‡æ¯å¼ : {avg_time:.2f}s")
    print(f"å¤„ç†é€Ÿåº¦: {batch_size / total_time:.1f} å›¾åƒ/ç§’")
    
    # éªŒè¯æ€§èƒ½è¦æ±‚
    assert avg_time < 2.0, f"å¹³å‡å¤„ç†æ—¶é—´è¿‡é•¿: {avg_time:.2f}s >= 2s"
    assert total_time < 30.0, f"æ€»å¤„ç†æ—¶é—´è¿‡é•¿: {total_time:.2f}s >= 30s"
    
    print("âœ… æ‰¹é‡å¤„ç†æ€§èƒ½æµ‹è¯•é€šè¿‡")
    return True


if __name__ == "__main__":
    try:
        print("å¼€å§‹ç«¯åˆ°ç«¯OCRå¤„ç†æµ‹è¯•...")
        
        # è¿è¡Œæ‰€æœ‰æµ‹è¯•
        test_end_to_end_ocr_processing()
        test_image_preprocessing_impact()
        test_batch_processing_performance()
        
        print("\nğŸ‰ æ‰€æœ‰ç«¯åˆ°ç«¯æµ‹è¯•å®Œæˆï¼")
        
    except Exception as e:
        print(f"âŒ æµ‹è¯•å¤±è´¥: {e}")
        import traceback
        traceback.print_exc()
        sys.exit(1)